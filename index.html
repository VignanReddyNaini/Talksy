<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Talksy: Bridging Communication</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            background-color: #f0f0f0;
            margin: 0;
            padding: 10px;
        }
        .container {
            display: flex;
            flex-direction: column;
            gap: 20px;
            max-width: 100%;
            width: 100%;
        }
        .video-section, .controls-section {
            background: #fff;
            padding: 15px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            width: calc(100% - 30px);
        }
        #canvas {
            border: 2px solid #333;
            border-radius: 8px;
            max-width: 100%;
            width: 100%;
            height: auto;
            aspect-ratio: 4/3;
        }
        .output, .button {
            margin: 10px 0;
        }
        .button button {
            padding: 12px 16px;
            margin-right: 10px;
            margin-bottom: 5px;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            font-size: 16px;
        }
        .button button:disabled {
            background: #ccc;
            cursor: not-allowed;
        }
        #startSign { background-color: #ff4d4d; color: white; }
        #stopSign { background-color: #808080; color: white; }
        #clearAll { background-color: #808080; color: white; }
        #startSpeech { background-color: #4CAF50; color: white; }
        #stopSpeech { background-color: #808080; color: white; }
        #startTTS { background-color: #ff4d4d; color: white; }
        #stopTTS { background-color: #808080; color: white; }
        h1 { color: #1E90FF; text-align: center; font-size: 24px; }
        #error { color: red; margin: 10px 0; }
        #permissionRequest {
            display: none;
            background-color: #ffeb3b;
            padding: 10px;
            margin: 10px 0;
            border-radius: 8px;
            text-align: center;
        }
        #permissionButton {
            background-color: #4CAF50;
            color: white;
            padding: 10px 15px;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            font-size: 16px;
            margin-top: 10px;
        }
        
        /* Media Queries for better mobile layout */
        @media (min-width: 768px) {
            .container {
                flex-direction: row;
                flex-wrap: wrap;
                justify-content: center;
            }
            .video-section, .controls-section {
                width: 320px;
            }
            #canvas {
                width: 320px;
                height: 240px;
                aspect-ratio: auto;
            }
        }
    </style>
</head>
<body>
    <div id="permissionRequest">
        <p>This app needs camera access to detect sign language gestures.</p>
        <button id="permissionButton">Grant Camera Access</button>
    </div>
    
    <div class="container">
        <div class="video-section">
            <h1>Talksy: Bridging Communication</h1>
            <canvas id="canvas"></canvas>
            <div class="output">Word: <span id="wordOutput">None</span></div>
            <div class="button">
                <button id="startSign">Start Sign</button>
                <button id="stopSign" disabled>Stop Sign</button>
            </div>
            <div id="error"></div>
        </div>
        <div class="controls-section">
            <div class="output">Speech-to-Text</div>
            <div class="output">Spoken Text: <span id="spokenText">None</span></div>
            <div class="button">
                <button id="startSpeech">Start Speech</button>
                <button id="stopSpeech" disabled>Stop Speech</button>
            </div>
            <div class="output">Text-to-Speech</div>
            <input type="text" id="ttsInput" placeholder="Type here to speak" style="width: 100%; padding: 10px; font-size: 16px;">
            <div class="output">TTS Status: <span id="ttsStatus">Inactive</span></div>
            <div class="button">
                <button id="startTTS">Start TTS</button>
                <button id="stopTTS" disabled>Stop TTS</button>
                <button id="clearAll">Clear All</button>
            </div>
        </div>
    </div>

    <!-- Load TensorFlow.js -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.18.0/dist/tf.min.js"></script>
    
    <!-- Load MediaPipe libraries correctly -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands@0.4.1646424915/hands.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils@0.3/camera_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils@0.3/drawing_utils.js"></script>
    
    <!-- Include ResponsiveVoice with a free non-commercial key -->
    <script src="https://code.responsivevoice.org/responsivevoice.js?key=nWH1ced6"></script>
    
    <script>
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        const wordOutput = document.getElementById('wordOutput');
        const errorDiv = document.getElementById('error');
        const startSign = document.getElementById('startSign');
        const stopSign = document.getElementById('stopSign');
        const startSpeech = document.getElementById('startSpeech');
        const stopSpeech = document.getElementById('stopSpeech');
        const spokenText = document.getElementById('spokenText');
        const ttsInput = document.getElementById('ttsInput');
        const startTTS = document.getElementById('startTTS');
        const stopTTS = document.getElementById('stopTTS');
        const ttsStatus = document.getElementById('ttsStatus');
        const clearAll = document.getElementById('clearAll');
        const permissionRequest = document.getElementById('permissionRequest');
        const permissionButton = document.getElementById('permissionButton');
        
        let video;
        let camera = null;
        let hands = null;
        let recognition = null;
        let isTTSActive = false;
        let isPredicting = false;
        let hasPermission = false;
        let isMobile = window.innerWidth < 768;

        // Set canvas dimensions based on device
        function setCanvasDimensions() {
            isMobile = window.innerWidth < 768;
            
            if (isMobile) {
                // Mobile layout
                canvas.width = canvas.offsetWidth;
                canvas.height = canvas.offsetWidth * 0.75; // 4:3 aspect ratio
            } else {
                // Desktop layout
                canvas.width = 320;
                canvas.height = 240;
            }
            
            // If the context exists, restore the mirroring for video feed
            if (ctx) {
                // Clear the canvas after resize
                ctx.clearRect(0, 0, canvas.width, canvas.height);
            }
        }

        // Handle window resize
        window.addEventListener('resize', setCanvasDimensions);
        
        // Initialize canvas dimensions on load
        setCanvasDimensions();

        // Handle permissions explicitly
        permissionButton.addEventListener('click', async () => {
            permissionRequest.style.display = 'none';
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    video: { 
                        facingMode: 'user',
                        width: { ideal: 320 },
                        height: { ideal: 240 }
                    } 
                });
                hasPermission = true;
                stream.getTracks().forEach(track => track.stop()); // Stop the temporary stream
                errorDiv.textContent = 'Camera permission granted. Click "Start Sign" to begin.';
                errorDiv.style.color = 'green';
            } catch (err) {
                errorDiv.textContent = 'Camera permission denied: ' + err.message;
                console.error('Permission error:', err);
            }
        });

        // Set up webcam and draw to canvas
        async function setupCamera() {
            try {
                errorDiv.textContent = 'Initializing camera...';
                
                if (!hasPermission) {
                    // First check if permission is granted
                    try {
                        const stream = await navigator.mediaDevices.getUserMedia({ 
                            video: { 
                                facingMode: 'user',
                                width: { ideal: 320 },
                                height: { ideal: 240 }
                            } 
                        });
                        hasPermission = true;
                        stream.getTracks().forEach(track => track.stop()); // Stop the temporary stream
                    } catch (err) {
                        if (err.name === 'NotAllowedError' || err.name === 'PermissionDeniedError') {
                            permissionRequest.style.display = 'block';
                            throw new Error('Camera permission needed');
                        } else {
                            throw err;
                        }
                    }
                }
                
                // Create video element
                video = document.createElement('video');
                video.width = canvas.width;
                video.height = canvas.height;
                video.autoplay = true;
                
                // Try to get stream with specific constraints for mobile
                const constraints = {
                    video: {
                        facingMode: 'user',
                        width: { ideal: canvas.width },
                        height: { ideal: canvas.height }
                    }
                };
                
                const stream = await navigator.mediaDevices.getUserMedia(constraints);
                video.srcObject = stream;
                
                // Wait for video to be ready
                return new Promise((resolve) => {
                    video.onloadedmetadata = () => {
                        video.play()
                            .then(() => {
                                errorDiv.textContent = 'Camera initialized successfully!';
                                errorDiv.style.color = 'green';
                                
                                // Initialize MediaPipe Hands
                                initializeHandTracking();
                                resolve(video);
                            })
                            .catch(err => {
                                errorDiv.textContent = 'Error playing video: ' + err.message;
                                throw err;
                            });
                    };
                });
            } catch (err) {
                if (err.name === 'NotReadableError') {
                    errorDiv.textContent = 'Camera error: The camera may be in use by another application. Please close other camera apps and try again.';
                } else {
                    errorDiv.textContent = 'Camera setup error: ' + err.message;
                }
                console.error('Camera setup error:', err);
                throw err;
            }
        }
        
        // Initialize hand tracking with MediaPipe
        function initializeHandTracking() {
            try {
                // Initialize MediaPipe Hands module
                if (!window.Hands) {
                    throw new Error("MediaPipe Hands module not loaded correctly");
                }
                
                hands = new window.Hands({
                    locateFile: (file) => {
                        return `https://cdn.jsdelivr.net/npm/@mediapipe/hands@0.4.1646424915/${file}`;
                    }
                });
                
                hands.setOptions({
                    maxNumHands: 1,
                    minDetectionConfidence: 0.6, // Lower threshold for better detection on mobile
                    minTrackingConfidence: 0.6,
                    modelComplexity: 1
                });
                
                hands.onResults(onResults);

                // Initialize camera utilities
                if (!window.Camera) {
                    throw new Error("MediaPipe Camera module not loaded correctly");
                }
                
                camera = new window.Camera(video, {
                    onFrame: async () => {
                        if (isPredicting && hands) {
                            await hands.send({image: video});
                        }
                    },
                    width: canvas.width,
                    height: canvas.height
                });
                
            } catch (err) {
                errorDiv.textContent = 'Hand tracking initialization error: ' + err.message;
                console.error('Hand tracking setup error:', err);
                throw err;
            }
        }

        // Process hand landmarks - FIXED VERSION FOR CORRECT ALIGNMENT
        function onResults(results) {
            // Clear the canvas first
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            
            // Draw the mirrored video feed
            ctx.save();
            ctx.scale(-1, 1); // Mirror horizontally
            ctx.translate(-canvas.width, 0);
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
            ctx.restore();
            
            if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
                const landmarks = results.multiHandLandmarks[0];
                
                // FIXED: Apply consistent mirroring for both video and landmarks
                ctx.save();
                ctx.scale(-1, 1);
                ctx.translate(-canvas.width, 0);
                
                // Draw connections between landmarks (lines)
                if (window.drawConnectors && window.HAND_CONNECTIONS) {
                    window.drawConnectors(ctx, landmarks, window.HAND_CONNECTIONS, 
                        {color: '#00FF00', lineWidth: 2});
                }
                
                // Draw landmarks (points)
                if (window.drawLandmarks) {
                    window.drawLandmarks(ctx, landmarks, 
                        {color: '#FF0000', lineWidth: 1, radius: 3});
                } else {
                    // Fallback to manual drawing if MediaPipe drawing utils aren't available
                    for (let landmark of landmarks) {
                        ctx.fillStyle = '#FF0000';
                        ctx.beginPath();
                        ctx.arc(
                            landmark.x * canvas.width,
                            landmark.y * canvas.height,
                            3, 0, 2 * Math.PI
                        );
                        ctx.fill();
                    }
                }
                
                ctx.restore();

                // Gesture recognition rules
                const gesture = detectGesture(landmarks);
                wordOutput.textContent = `${gesture}`;
            } else {
                wordOutput.textContent = 'None';
            }
        }

        // Detect gesture based on landmarks - improved for mobile detection
        function detectGesture(landmarks) {
            // Calculate finger states with improved thresholds for mobile
            const fingerTipPositions = [
                { name: 'thumb', tip: 4, pip: 3, threshold: 0.09 },
                { name: 'index', tip: 8, pip: 6, threshold: 0.06 },
                { name: 'middle', tip: 12, pip: 10, threshold: 0.06 },
                { name: 'ring', tip: 16, pip: 14, threshold: 0.06 },
                { name: 'pinky', tip: 20, pip: 18, threshold: 0.06 }
            ];
            
            const fingers = {};
            
            // Determine if fingers are extended
            fingerTipPositions.forEach(finger => {
                if (finger.name === 'thumb') {
                    // Special case for thumb - check both y position and x distance
                    fingers.thumb = (landmarks[finger.tip].y < landmarks[finger.pip].y) && 
                                    (Math.abs(landmarks[finger.tip].x - landmarks[finger.pip].x) > finger.threshold);
                } else {
                    // For other fingers, simply check if tip is above pip (knuckle)
                    fingers[finger.name] = landmarks[finger.tip].y < landmarks[finger.pip].y;
                }
            });

            // Define gesture rules with clearer logic for mobile detection
            if (fingers.thumb && !fingers.index && !fingers.middle && !fingers.ring && !fingers.pinky) {
                return 'Thank You'; // Thumb up, others curled
            } else if (fingers.index && fingers.middle && !fingers.thumb && !fingers.ring && !fingers.pinky) {
                return 'Bad'; // Index and middle up, others curled
            } else if (fingers.index && fingers.middle && fingers.ring && !fingers.thumb && !fingers.pinky) {
                return 'Good'; // Index, middle, ring up, others curled
            } else if (fingers.index && !fingers.thumb && !fingers.middle && !fingers.ring && !fingers.pinky) {
                return 'No'; // Index up, others curled
            } else if (fingers.thumb && fingers.index && 
                      (Math.abs(landmarks[4].x - landmarks[8].x) < 0.1) &&
                      (landmarks[4].y > landmarks[8].y) && 
                      !fingers.middle && !fingers.ring && !fingers.pinky) {
                return 'Hello'; // Thumb and index forming a circle
            } else if (!fingers.thumb && fingers.index && fingers.middle && fingers.ring && fingers.pinky) {
                return 'Yes'; // Four fingers up with thumb closed
            } else if (fingers.thumb && fingers.index && fingers.middle && fingers.ring && fingers.pinky) {
                return 'Open Hand'; // All fingers spread
            }
            return 'None';
        }

        // Start gesture recognition
        startSign.addEventListener('click', async () => {
            try {
                startSign.disabled = true;
                stopSign.disabled = false;
                errorDiv.textContent = 'Starting camera...';
                
                if (!camera || !video) {
                    await setupCamera();
                    if (camera) {
                        await camera.start();
                        isPredicting = true;
                    } else {
                        throw new Error("Failed to initialize camera");
                    }
                } else {
                    // If camera already initialized, just start it
                    await camera.start();
                    isPredicting = true;
                }
            } catch (err) {
                errorDiv.textContent = 'Error starting camera: ' + err.message;
                startSign.disabled = false;
                stopSign.disabled = true;
            }
        });

        // Stop gesture recognition
        stopSign.addEventListener('click', () => {
            startSign.disabled = false;
            stopSign.disabled = true;
            if (camera) {
                camera.stop();
            }
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            isPredicting = false;
            wordOutput.textContent = 'None';
        });

        // Speech-to-Text using Web Speech API
        startSpeech.addEventListener('click', () => {
            if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
                errorDiv.textContent = 'Speech recognition not supported in this browser.';
                return;
            }
            
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            recognition = new SpeechRecognition();
            recognition.continuous = true;
            recognition.interimResults = false;
            recognition.lang = 'en-US';

            recognition.onresult = (event) => {
                const result = event.results[event.results.length - 1][0].transcript;
                spokenText.textContent = result;
            };

            recognition.onerror = (event) => {
                errorDiv.textContent = 'Speech recognition error: ' + event.error;
            };

            recognition.onend = () => {
                // Only reset buttons if stop was not manually pressed
                if (!startSpeech.disabled) return;
                
                startSpeech.disabled = false;
                stopSpeech.disabled = true;
            };

            startSpeech.disabled = true;
            stopSpeech.disabled = false;
            recognition.start();
        });

        stopSpeech.addEventListener('click', () => {
            if (recognition) {
                recognition.stop();
                startSpeech.disabled = false;
                stopSpeech.disabled = true;
            }
        });

        // Text-to-Speech with fallback mechanism
        startTTS.addEventListener('click', () => {
            const text = ttsInput.value.trim();
            if (text) {
                // Try ResponsiveVoice first
                if (typeof responsiveVoice !== 'undefined' && responsiveVoice) {
                    try {
                        responsiveVoice.speak(text, "US English Female", {
                            onstart: () => {
                                ttsStatus.textContent = 'Active';
                                isTTSActive = true;
                                startTTS.disabled = true;
                                stopTTS.disabled = false;
                            },
                            onend: () => {
                                ttsStatus.textContent = 'Inactive';
                                isTTSActive = false;
                                startTTS.disabled = false;
                                stopTTS.disabled = true;
                            }
                        });
                    } catch (e) {
                        console.error("ResponsiveVoice error:", e);
                        useBrowserTTS(text);
                    }
                } else {
                    // Fallback to browser's native speech synthesis
                    useBrowserTTS(text);
                }
            } else {
                errorDiv.textContent = 'Please enter text to speak.';
            }
        });

        // Browser's native TTS function
        function useBrowserTTS(text) {
            if ('speechSynthesis' in window) {
                const utterance = new SpeechSynthesisUtterance(text);
                utterance.lang = 'en-US';
                utterance.onstart = () => {
                    ttsStatus.textContent = 'Active';
                    isTTSActive = true;
                    startTTS.disabled = true;
                    stopTTS.disabled = false;
                };
                utterance.onend = () => {
                    ttsStatus.textContent = 'Inactive';
                    isTTSActive = false;
                    startTTS.disabled = false;
                    stopTTS.disabled = true;
                };
                speechSynthesis.speak(utterance);
            } else {
                errorDiv.textContent = 'Text-to-speech not supported in this browser.';
                startTTS.disabled = false;
                stopTTS.disabled = true;
            }
        }

        stopTTS.addEventListener('click', () => {
            if (typeof responsiveVoice !== 'undefined' && responsiveVoice) {
                try {
                    responsiveVoice.cancel();
                } catch (e) {
                    console.error("ResponsiveVoice error on cancel:", e);
                }
            }
            
            // Also cancel browser's native speech synthesis
            if ('speechSynthesis' in window) {
                speechSynthesis.cancel();
            }
            
            ttsStatus.textContent = 'Inactive';
            isTTSActive = false;
            startTTS.disabled = false;
            stopTTS.disabled = true;
        });

        // Clear All
        clearAll.addEventListener('click', () => {
            wordOutput.textContent = 'None';
            spokenText.textContent = 'None';
            ttsInput.value = '';
            ttsStatus.textContent = 'Inactive';
            errorDiv.textContent = '';
            
            if (isTTSActive) {
                if (typeof responsiveVoice !== 'undefined' && responsiveVoice) {
                    try {
                        responsiveVoice.cancel();
                    } catch (e) {
                        console.error("ResponsiveVoice error on cancel:", e);
                    }
                }
                
                // Also cancel browser's native speech synthesis
                if ('speechSynthesis' in window) {
                    speechSynthesis.cancel();
                }
                
                startTTS.disabled = false;
                stopTTS.disabled = true;
                isTTSActive = false;
            }
            
            if (recognition && !stopSpeech.disabled) {
                recognition.stop();
                startSpeech.disabled = false;
                stopSpeech.disabled = true;
            }
            
            if (isPredicting) {
                isPredicting = false;
                startSign.disabled = false;
                stopSign.disabled = true;
                if (camera) camera.stop();
                ctx.clearRect(0, 0, canvas.width, canvas.height);
            }
        });

        // Initialize application on document load
        document.addEventListener('DOMContentLoaded', function() {
            // Check if MediaPipe modules are available
            if (!window.Hands) {
                errorDiv.textContent = 'MediaPipe Hands module not loaded. Sign language detection will not work.';
            }
            
            if (!window.Camera) {
                errorDiv.textContent += ' MediaPipe Camera module not loaded.';
            }
            
            // Display browser info for debugging
            const userAgent = navigator.userAgent;
            console.log("User Agent:", userAgent);
            console.log("Is Mobile:", isMobile);
            
            // Check if running on HTTPS
            if (location.protocol !== 'https:' && location.hostname !== 'localhost' && location.hostname !== '127.0.0.1') {
                errorDiv.textContent = 'Warning: Camera access requires HTTPS for security. This site may not work properly.';
            }
        });

        // Main function
        function main() {
            console.log("Talksy application initialized. Click 'Start Sign' to begin sign language detection.");
        }

        main();
    </script>
</body>
</html>
